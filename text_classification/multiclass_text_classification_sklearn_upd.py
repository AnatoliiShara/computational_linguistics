# -*- coding: utf-8 -*-
"""multiclass_text_classification_sklearn_upd.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O3PQQnbA8EXb-Y-7BACd7AJfXBhfy_6E
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_selection import chi2
from sklearn.metrics import classification_report
from sklearn.pipeline import Pipeline
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC

# Read the CSV file and preprocess the data
df = pd.read_csv("rows.csv", nrows=80000)
df = df.dropna(subset=['Consumer complaint narrative'])
col = ['Product', 'Consumer complaint narrative']
df = df[col]
df.columns = ['Product', 'Consumer_complaint_narrative']
df['category_id'] = df['Product'].factorize()[0]

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(df['Consumer_complaint_narrative'], df['category_id'], random_state=42)

# Define a pipeline for text classification
text_clf = Pipeline([
    ('tfidf', TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin1', ngram_range=(1, 2), stop_words='english')),
    ('clf', MultinomialNB())  # You can change the classifier here
])

# Use GridSearchCV to find the best hyperparameters
param_grid = {
    'tfidf__ngram_range': [(1, 1), (1, 2)],
    'clf__alpha': [1, 0.1, 0.01]
}

grid_search = GridSearchCV(text_clf, param_grid, cv=5)
grid_search.fit(X_train, y_train)

# Print the best parameters and accuracy
print("Best parameters found: ", grid_search.best_params_)
print("Best cross-validation accuracy: {:.2f}%".format(grid_search.best_score_ * 100))

# Evaluate the model on the test set
y_pred = grid_search.predict(X_test)
print("Test set accuracy: {:.2f}%".format(np.mean(y_pred == y_test) * 100))

# Print classification report
print(classification_report(y_test, y_pred))

# Train and evaluate other classifiers
models = [
    ('Random Forest', RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0)),
    ('Linear SVC', LinearSVC()),
    ('Logistic Regression', LogisticRegression(random_state=0))
]

for name, model in models:
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = np.mean(y_pred == y_test) * 100
    print(f"{name} Test Set Accuracy: {accuracy:.2f}%")















