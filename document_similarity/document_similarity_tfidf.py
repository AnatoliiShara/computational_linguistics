# -*- coding: utf-8 -*-
"""document_similarity_tfidf.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16YXmwkvMImx2wuGt6j9naBVimEKEJ71q
"""

import spacy
from typing import List, Tuple
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

nlp = spacy.load("en_core_web_sm")

base_document = "This is an example sentence for the document to be compared. Document similarity in NLP"

documents = [
    "This is the first document",
    "A quick brown fox jumps over the lazy dog.",
    "A lazy dog barks at the moon.",
    "Document similarity is important for many NLP tasks.",
    "Natural Language Processing (NLP) is a fascinating field.",
    "This is the collection of documents to be compared against the base_document",
    "Politics can be a complex and divisive topic in society today.",
    "Sport brings people together and promotes a healthy lifestyle.",
    "Education is the key to unlocking a bright future for individuals.",
    "Kyiv, the capital of Ukraine, is known for its rich history and culture."

]

def preprocess_text(text: str) -> List[str]:
  doc = nlp(text)
  words = []
  for token in doc:
    if not token.is_stop and not token.is_punct and len(token) > 1:
      words.append(token.lemma_.lower())
  return words

def calculate_tfidf_similarity(base_doc: str, docs: List[str]) -> Tuple[str, float, str, float]:
  vectorizer = TfidfVectorizer()
  # to make uniformed vectors, both documents need to be combined firts
  docs.insert(0, base_doc)
  embeddings = vectorizer.fit_transform(docs)

  cosine_similarities = cosine_similarity(embeddings[0: 1], embeddings[1:])

  highest_score = max(cosine_similarities)
  highest_score_index = cosine_similarities.argmax()
  most_similar_document = docs[highest_score_index]

  lowest_score = min(cosine_similarities)
  lowest_score_index = cosine_similarities.argmin()
  least_similar_document = docs[lowest_score_index]

  return most_similar_document, highest_score, least_similar_document, lowest_score

def print_keywords_pairs(document: str, base_document: str) -> None:
  vectorizer = TfidfVectorizer()
  embeddings = vectorizer.fit_transform([document, base_document])
  feature_names = vectorizer.get_feature_names_out()

  tfidf_values = embeddings.toarray()[0]

  keywords_pairs = [(feature_names[i], tfidf_values[i]) for i in range(len(feature_names))]
  keywords_pairs.sort(key=lambda x: x[1], reverse=True)

  print("\nKeyword pairs for the Document")
  for keyword, tfidf in keywords_pairs:
    print(f"{keyword}: {tfidf:.4f}")

def main():
  most_similar_doc, highest_score, least_similar_document, lowest_score = calculate_tfidf_similarity(base_document, documents)

  print("Most similar document by TFIDF with score:", most_similar_doc, highest_score)
  print("Least similar document by TFIDF with score: ", least_similar_document, lowest_score)

  print_keywords_pairs(most_similar_doc, base_document)
  print_keywords_pairs(least_similar_document, base_document)

if __name__ == "__main__":
  main()





